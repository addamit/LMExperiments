{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/addamit/LMExperiments/blob/main/FineTuningForFunctionCalling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43b502c1-9548-4580-84ad-1cbac158edb8",
      "metadata": {
        "id": "43b502c1-9548-4580-84ad-1cbac158edb8"
      },
      "source": [
        "Fine-Tuning a model for Function-Calling. Originally from\n",
        "https://huggingface.co/agents-course/notebooks/blob/main/bonus-unit1/bonus-unit1.ipynb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e63f4962-c644-491e-aa91-50e453e953a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e63f4962-c644-491e-aa91-50e453e953a4",
        "outputId": "fea730f5-315a-41f8-d662-9779b0b8a994",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.0/411.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.7/335.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U peft\n",
        "!pip install -q -U trl\n",
        "!pip install -q -U tensorboardX\n",
        "!pip install -q wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UWNoZzi1urSZ",
      "metadata": {
        "id": "UWNoZzi1urSZ"
      },
      "source": [
        " Hugging Face Token to push model to the Hub\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vBAkwg9zu6A1",
      "metadata": {
        "id": "vBAkwg9zu6A1"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ad2e4c2-593e-463e-9692-8d674c541d76",
      "metadata": {
        "id": "7ad2e4c2-593e-463e-9692-8d674c541d76",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from enum import Enum\n",
        "from functools import partial\n",
        "import pandas as pd\n",
        "import torch\n",
        "import json\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed\n",
        "from datasets import load_dataset\n",
        "from trl import SFTConfig, SFTTrainer\n",
        "from peft import LoraConfig, TaskType\n",
        "\n",
        "seed = 42\n",
        "set_seed(seed)\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ['HF_TOKEN']=\"hf_xxxx\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44f30b2c-2cc0-48e0-91ca-4633e6444105",
      "metadata": {
        "id": "44f30b2c-2cc0-48e0-91ca-4633e6444105"
      },
      "source": [
        "## Processing the dataset into inputs\n",
        "\n",
        "In order to train the model, we need to **format the inputs into what we want the model to learn**.\n",
        "\n",
        " \"NousResearch/hermes-function-calling-v1\" enhanced to some new **thinking** step computer from **deepseek-ai/DeepSeek-R1-Distill-Qwen-32B**.\n",
        "\n",
        "But in order for the model to learn, we need **to format the conversation correctly**.  **chat_template**, or, the default chat_template of gemma-2-2B does not contain tool calls. So we will need to modify it !\n",
        "\n",
        "This is the role of our **preprocess** function. To go from a list of messages, to a prompt that the model can understand.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29da85c8-33bf-4864-aed7-733cbe703512",
      "metadata": {
        "id": "29da85c8-33bf-4864-aed7-733cbe703512",
        "tags": [],
        "outputId": "c2b07f38-743b-493d-9ff5-d5fe97cb4736",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_name = \"google/gemma-2-2b-it\"\n",
        "dataset_name = \"Jofthomas/hermes-function-calling-thinking-V1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "tokenizer.chat_template = \"{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{{ '<start_of_turn>' + message['role'] + '\\n' + message['content'] | trim + '<end_of_turn><eos>\\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\\n'}}{% endif %}\"\n",
        "\n",
        "\n",
        "def preprocess(sample):\n",
        "      messages = sample[\"messages\"]\n",
        "      first_message = messages[0]\n",
        "\n",
        "      # Instead of adding a system message, we merge the content into the first user message\n",
        "      if first_message[\"role\"] == \"system\":\n",
        "          system_message_content = first_message[\"content\"]\n",
        "          # Merge system content with the first user message\n",
        "          messages[1][\"content\"] = system_message_content + \"Also, before making a call to a function take the time to plan the function to take. Make that thinking process between <think>{your thoughts}</think>\\n\\n\" + messages[1][\"content\"]\n",
        "          # Remove the system message from the conversation\n",
        "          messages.pop(0)\n",
        "\n",
        "      return {\"text\": tokenizer.apply_chat_template(messages, tokenize=False)}\n",
        "\n",
        "\n",
        "\n",
        "dataset = load_dataset(dataset_name)\n",
        "dataset = dataset.rename_column(\"conversations\", \"messages\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc8736d5-d64b-4c5c-9738-be08421d3f95",
      "metadata": {
        "id": "dc8736d5-d64b-4c5c-9738-be08421d3f95"
      },
      "source": [
        "\n",
        "\n",
        " custom dataset based on [NousResearch/hermes-function-calling-v1](https://huggingface.co/datasets/NousResearch/hermes-function-calling-v1), which is considered a **reference** when it comes to function-calling datasets.\n",
        "\n",
        "While the original dataset is excellent, it does **not** include a **“thinking”** step.\n",
        "\n",
        "In Function-Calling, such a step is optional, but recent work—like the **deepseek** model or the paper [\"Test-Time Compute\"](https://huggingface.co/papers/2408.03314)—suggests that giving an LLM time to “think” before it answers (or in this case, **before** taking an action) can **significantly improve** model performance.\n",
        "\n",
        "For dataset author decided to compute a subset of this dataset and to give it to [deepseek-ai/DeepSeek-R1-Distill-Qwen-32B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B) in order to compute some thinking tokens `<think>` before any function call. Which resulted in the following dataset :\n",
        "![Input Dataset](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/bonus-unit1/dataset_function_call.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b63d4832-d92e-482d-9fe6-6e9dbfee377a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b63d4832-d92e-482d-9fe6-6e9dbfee377a",
        "outputId": "991d80d5-e4da-4014-ebd7-488d8c8bd526",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 3213\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 357\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "dataset = dataset.map(preprocess, remove_columns=\"messages\")\n",
        "dataset = dataset[\"train\"].train_test_split(0.1)\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67724a23-f298-4247-b002-2cf370b03897",
      "metadata": {
        "id": "67724a23-f298-4247-b002-2cf370b03897"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "1. A *User message* containing the **necessary information with the list of available tools** inbetween `<tools></tools>` then the user query, here:  `\"Can you get me the latest news headlines for the United States?\"`\n",
        "\n",
        "2. An *Assistant message* here called \"model\" to fit the criterias from gemma models containing two new phases, a **\"thinking\"** phase contained in `<think></think>` and an **\"Act\"** phase contained in `<tool_call></<tool_call>`.\n",
        "\n",
        "3. If the model contains a `<tools_call>`, we will append the result of this action in a new **\"Tool\"** message containing a `<tool_response></tool_response>` with the answer from the tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc60da04-9411-487a-b629-2c59024a20c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc60da04-9411-487a-b629-2c59024a20c0",
        "outputId": "7616d3ff-b964-424e-cad6-4efdf18b9f3b",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bos><start_of_turn>human\n",
            "You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags.You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions.Here are the available tools:<tools> [{'type': 'function', 'function': {'name': 'get_road_traffic', 'description': 'Get information about road traffic', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The location to get traffic information for'}, 'date': {'type': 'string', 'description': 'The date to get traffic information for'}}, 'required': ['location']}}}, {'type': 'function', 'function': {'name': 'calculate_tax', 'description': 'Calculate the tax amount based on income and tax rate', 'parameters': {'type': 'object', 'properties': {'income': {'type': 'number', 'description': 'The income amount'}, 'tax_rate': {'type': 'number', 'description': 'The tax rate percentage'}}, 'required': ['income', 'tax_rate']}}}] </tools>Use the following pydantic model json schema for each tool call you will make: {'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
            "<tool_call>\n",
            "{tool_call}\n",
            "</tool_call>Also, before making a call to a function take the time to plan the function to take. Make that thinking process between <think>{your thoughts}</think>\n",
            "\n",
            "Hi, I need to know the traffic situation in New York for tomorrow.<end_of_turn><eos>\n",
            "<start_of_turn>model\n",
            "<think>Alright, let's break down the thought process here. The user has asked about the traffic situation in New York for tomorrow. Looking at the available tools, the get_road_traffic function is the most suitable because it's designed to provide information about road traffic. \n",
            "\n",
            "The function requires a location and an optional date. The user provided both, specifying \"New York\" as the location and \"tomorrow\" as the date. Even though \"date\" is optional, including it ensures the most accurate and relevant information for the user's query. \n",
            "\n",
            "So, the logical step is to call get_road_traffic with the provided details to fetch the specific traffic data requested.\n",
            "</think><tool_call>\n",
            "{'name': 'get_road_traffic', 'arguments': {'location': 'New York', 'date': 'tomorrow'}}\n",
            "</tool_call><end_of_turn><eos>\n",
            "<start_of_turn>tool\n",
            "<tool_response>\n",
            "{'status': 'success', 'data': {'location': 'New York', 'date': 'tomorrow', 'traffic': 'Moderate', 'peak_hours': '8 AM - 10 AM, 5 PM - 7 PM'}}\n",
            "</tool_response><end_of_turn><eos>\n",
            "<start_of_turn>model\n",
            "The traffic in New York for tomorrow is expected to be moderate. The peak hours will be from 8 AM to 10 AM and from 5 PM to 7 PM. Please plan your travel accordingly.<end_of_turn><eos>\n",
            "<start_of_turn>human\n",
            "Thanks for the information. Can you also tell me the traffic situation in Los Angeles for today?<end_of_turn><eos>\n",
            "<start_of_turn>model\n",
            "<think>Okay, let's break down the user's request step by step. The user initially asked about the traffic situation in New York for tomorrow. Using the available tools, I identified that the `get_road_traffic` function was the best fit because it retrieves road traffic information based on location and date. I called this function with the provided details and received a successful response indicating moderate traffic during specific peak hours.\n",
            "\n",
            "Now, the user has followed up by thanking me and asking for the traffic situation in Los Angeles for today. This new query is similar to the first one but changes the location to Los Angeles and the date to today. Since the function `get_road_traffic` is already designed to handle different locations and dates, it makes sense to use it again for consistency and accuracy.\n",
            "\n",
            "I considered whether any other functions, like `calculate_tax`, would be relevant, but they don't apply here. The user's query is specifically about traffic, so `get_road_traffic` remains the appropriate tool. By structuring the function call with the new location and date, I ensure that the user receives precise and timely information tailored to their needs.\n",
            "\n",
            "It's important to maintain clarity and specificity in each function call to avoid fetching unnecessary data. Providing accurate and relevant traffic updates helps the user plan their travel effectively, which aligns with the purpose of the function and the user's intent.\n",
            "</think><tool_call>\n",
            "{'name': 'get_road_traffic', 'arguments': {'location': 'Los Angeles', 'date': 'today'}}\n",
            "</tool_call><end_of_turn><eos>\n",
            "<start_of_turn>tool\n",
            "<tool_response>\n",
            "{'status': 'success', 'data': {'location': 'Los Angeles', 'date': 'today', 'traffic': 'Heavy', 'peak_hours': '7 AM - 9 AM, 4 PM - 6 PM'}}\n",
            "</tool_response><end_of_turn><eos>\n",
            "<start_of_turn>model\n",
            "The traffic in Los Angeles for today is expected to be heavy. The peak hours will be from 7 AM to 9 AM and from 4 PM to 6 PM. Please plan your travel accordingly.<end_of_turn><eos>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's look at how we formatted the dataset\n",
        "print(dataset[\"train\"][1][\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53a48281-2346-4dfb-ad60-cad85129ec9b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53a48281-2346-4dfb-ad60-cad85129ec9b",
        "outputId": "ac25080d-e6a1-40b0-a0f6-13f94e26e8ce",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pad>\n",
            "<eos>\n"
          ]
        }
      ],
      "source": [
        "# Sanity check\n",
        "print(tokenizer.pad_token)\n",
        "print(tokenizer.eos_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6864b36-6033-445a-b6e2-b6bb02e38e26",
      "metadata": {
        "id": "d6864b36-6033-445a-b6e2-b6bb02e38e26"
      },
      "source": [
        "\n",
        "\n",
        "The tokenizer splits text into sub-words by default. This is **not** what we want for our new special tokens!\n",
        "\n",
        "While we segmented our example using `<think>`, `<tool_call>`, and `<tool_response>`, the tokenizer does **not** yet treat them as whole tokens—it still tries to break them down into smaller pieces. To ensure the model correctly interprets our new format, we must **add these tokens** to our tokenizer.\n",
        "\n",
        "Additionally, since we changed the `chat_template` in our **preprocess** function to format conversations as messages within a prompt, we also need to modify the `chat_template` in the tokenizer to reflect these changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "833ba5d6-4c1e-4689-9fed-22cc03d2a63a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9a67179783d745b8a836e30ca9821143",
            "d42aaa00581a461f96928a2fdb9c9adf",
            "5e88178b56de467cbd19cdee3f675094",
            "b7ed19a7a6ba4fda8d0d483fdd6e48f6",
            "63e312f67e9b44c2950848012e0e6ff6",
            "6cb096dcc7144beab982d7449bdb7cf5",
            "9efbb12684a4449bb9569957dfdbf8c3",
            "7879a50638214dcbaffe3b6e95ad3322",
            "cbb19ca98e04493abad7867edc2a63bd",
            "e5d220c05ac34aa194cf838a45422649",
            "5b30f7da57de47ee97f6ee8bf9c35ba2"
          ]
        },
        "id": "833ba5d6-4c1e-4689-9fed-22cc03d2a63a",
        "outputId": "43203df9-7dc4-445c-a7cf-d92acba99c60",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a67179783d745b8a836e30ca9821143"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "class ChatmlSpecialTokens(str, Enum):\n",
        "    tools = \"<tools>\"\n",
        "    eotools = \"</tools>\"\n",
        "    think = \"<think>\"\n",
        "    eothink = \"</think>\"\n",
        "    tool_call=\"<tool_call>\"\n",
        "    eotool_call=\"</tool_call>\"\n",
        "    tool_response=\"<tool_reponse>\"\n",
        "    eotool_response=\"</tool_reponse>\"\n",
        "    pad_token = \"<pad>\"\n",
        "    eos_token = \"<eos>\"\n",
        "    @classmethod\n",
        "    def list(cls):\n",
        "        return [c.value for c in cls]\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "        model_name,\n",
        "        pad_token=ChatmlSpecialTokens.pad_token.value,\n",
        "        additional_special_tokens=ChatmlSpecialTokens.list()\n",
        "    )\n",
        "tokenizer.chat_template = \"{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{{ '<start_of_turn>' + message['role'] + '\\n' + message['content'] | trim + '<end_of_turn><eos>\\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\\n'}}{% endif %}\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
        "                                             attn_implementation='eager',\n",
        "                                             device_map=\"auto\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.resize_token_embeddings(len(tokenizer))\n"
      ],
      "metadata": {
        "id": "EO8SQaELYx_P",
        "outputId": "84bd6eb7-3ef1-4653-ea68-96a81e85a911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "id": "EO8SQaELYx_P",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacity of 14.74 GiB of which 498.12 MiB is free. Process 66297 has 14.25 GiB memory in use. Of the allocated memory 11.94 GiB is allocated by PyTorch, and 2.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-933d36c5c265>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_token_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mresize_token_embeddings\u001b[0;34m(self, new_num_tokens, pad_to_multiple_of, mean_resizing)\u001b[0m\n\u001b[1;32m   2650\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPointer\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0mEmbeddings\u001b[0m \u001b[0mModule\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2651\u001b[0m         \"\"\"\n\u001b[0;32m-> 2652\u001b[0;31m         \u001b[0mmodel_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resize_token_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_num_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_resizing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2653\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_num_tokens\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpad_to_multiple_of\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2654\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_resize_token_embeddings\u001b[0;34m(self, new_num_tokens, pad_to_multiple_of, mean_resizing)\u001b[0m\n\u001b[1;32m   2675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resize_token_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_num_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_resizing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m         \u001b[0mold_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_input_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2677\u001b[0;31m         new_embeddings = self._get_resized_embeddings(\n\u001b[0m\u001b[1;32m   2678\u001b[0m             \u001b[0mold_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_num_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_resizing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2679\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_get_resized_embeddings\u001b[0;34m(self, old_embeddings, new_num_tokens, pad_to_multiple_of, mean_resizing)\u001b[0m\n\u001b[1;32m   2832\u001b[0m                     )\n\u001b[1;32m   2833\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2834\u001b[0;31m                 self._init_added_embeddings_weights_with_mean(\n\u001b[0m\u001b[1;32m   2835\u001b[0m                     \u001b[0mold_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_embedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_num_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madded_num_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2836\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_init_added_embeddings_weights_with_mean\u001b[0;34m(self, old_embeddings, new_embeddings, old_embedding_dim, old_num_tokens, added_num_tokens)\u001b[0m\n\u001b[1;32m   3006\u001b[0m         \u001b[0mold_embeddings_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3007\u001b[0m         \u001b[0mmean_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_embeddings_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3008\u001b[0;31m         \u001b[0mold_centered_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_embeddings_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3009\u001b[0m         \u001b[0mcovariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_centered_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mold_centered_embeddings\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mold_num_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacity of 14.74 GiB of which 498.12 MiB is free. Process 66297 has 14.25 GiB memory in use. Of the allocated memory 11.94 GiB is allocated by PyTorch, and 2.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(torch.bfloat16)\n"
      ],
      "metadata": {
        "id": "0ZGoWwHwZBPn"
      },
      "id": "0ZGoWwHwZBPn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "X6DBY8AqxFLL",
      "metadata": {
        "id": "X6DBY8AqxFLL"
      },
      "source": [
        "\n",
        "This is we are going to define the parameter of our adapter. Those a the most important parameters in LoRA as they define the size and importance of the adapters we are training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "482d36ab-e326-4fd7-bc59-425abcca55e7",
      "metadata": {
        "id": "482d36ab-e326-4fd7-bc59-425abcca55e7",
        "tags": [],
        "outputId": "fd2569fc-b2b6-4da8-e965-7f7e9ebd29e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'TaskType' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-276c83d46c08>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                          \u001b[0mlora_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlora_dropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                          \u001b[0mtarget_modules\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gate_proj\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"q_proj\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"lm_head\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"o_proj\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"k_proj\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"embed_tokens\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"down_proj\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"up_proj\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"v_proj\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# wich layer in the transformers do we target ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                          task_type=TaskType.CAUSAL_LM)\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'TaskType' is not defined"
          ]
        }
      ],
      "source": [
        "from peft import LoraConfig\n",
        "\n",
        "# TODO: Configure LoRA parameters\n",
        "# r: rank dimension for LoRA update matrices (smaller = more compression)\n",
        "rank_dimension = 16\n",
        "# lora_alpha: scaling factor for LoRA layers (higher = stronger adaptation)\n",
        "lora_alpha = 64\n",
        "# lora_dropout: dropout probability for LoRA layers (helps prevent overfitting)\n",
        "lora_dropout = 0.05\n",
        "\n",
        "peft_config = LoraConfig(r=rank_dimension,\n",
        "                         lora_alpha=lora_alpha,\n",
        "                         lora_dropout=lora_dropout,\n",
        "                         target_modules=[\"gate_proj\",\"q_proj\",\"lm_head\",\"o_proj\",\"k_proj\",\"embed_tokens\",\"down_proj\",\"up_proj\",\"v_proj\"], # wich layer in the transformers do we target ?\n",
        "                         task_type=TaskType.CAUSAL_LM)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zdDR9hzgxPu2",
      "metadata": {
        "id": "zdDR9hzgxPu2"
      },
      "source": [
        "Defining the Trainer and the Fine-Tuning hyperparameters\n",
        "\n",
        "In this step, we define the Trainer, the class that we use to fine-tune our model and the hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3598b688-5a6f-437f-95ac-4794688cd38f",
      "metadata": {
        "id": "3598b688-5a6f-437f-95ac-4794688cd38f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "output_dir = \"gemma-2-2B-it-thinking-function_calling-V0\" # The directory where the trained model checkpoints, logs, and other artifacts will be saved. It will also be the default name of the model when pushed to the hub if not redefined later.\n",
        "per_device_train_batch_size = 1\n",
        "per_device_eval_batch_size = 1\n",
        "gradient_accumulation_steps = 4\n",
        "logging_steps = 5\n",
        "learning_rate = 1e-4 # The initial learning rate for the optimizer.\n",
        "\n",
        "max_grad_norm = 1.0\n",
        "num_train_epochs=1\n",
        "warmup_ratio = 0.1\n",
        "lr_scheduler_type = \"cosine\"\n",
        "max_seq_length = 1500\n",
        "\n",
        "training_arguments = SFTConfig(\n",
        "    output_dir=output_dir,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    per_device_eval_batch_size=per_device_eval_batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    save_strategy=\"no\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    logging_steps=logging_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    max_grad_norm=max_grad_norm,\n",
        "    weight_decay=0.1,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "    lr_scheduler_type=lr_scheduler_type,\n",
        "    report_to=\"tensorboard\",\n",
        "    bf16=True,\n",
        "    hub_private_repo=False,\n",
        "    push_to_hub=False,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    gradient_checkpointing=True,\n",
        "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
        "    packing=True,\n",
        "    max_seq_length=max_seq_length,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59TTqmW2xmV2",
      "metadata": {
        "id": "59TTqmW2xmV2"
      },
      "source": [
        "As Trainer, we use the `SFTTrainer` which is a Supervised Fine-Tuning Trainer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba0366b5-c9d0-4f7e-97e0-1f964cfad147",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263,
          "referenced_widgets": [
            "e3fe61834c3e49a3895212a336776f9d",
            "472cbf91b24f46829960d68e2316c417",
            "bd746ea2e46a491e954ac6f32fb0e45b",
            "b1542891fc6243d98d51981dd0584bdf",
            "b2e16ad7540d4760b28f3a8c419905f8",
            "f2157c83879046a29b72613bce9de56e",
            "3b07ec7f4d024b61abe94c8adeebed55",
            "e6f810bd430245b190ee932554cca05c",
            "952893c941c346c2aedcd9358859a3b9",
            "d36e7dd4b9dc497faa6e8f63843a738f",
            "f469ec8c79ac476c82a5e228f347bffa",
            "e9de72aadc5743a2b56537b3ad035461",
            "57d137229091486dbf0e4b7dd6dce98a",
            "4d006dc72b2b45b58caf4d398c3756b8",
            "36bbd4bd563a4053a7af8532300253b7",
            "cacc3c3a10c64b338866a8e42201e44c",
            "b4c43d908bd64d9bbdb488dac46d2e45",
            "96691a6287ef401582a2a1744a4940c4",
            "328fa6d902bd46bbb0ecdc7404a13e8c",
            "f375fed157034dfcbd28744027d77eba",
            "33ec043a635f4e99b67cd6f7e6fc6193",
            "39fee7a249c146d1a166e58755c1cda8",
            "2ccddb85840c4981ae089ae4c74a2de6",
            "89eee480405a416ba0edf097423724b9",
            "56e8079c374a4f3f9af5ef96a73f2955",
            "3aeb28bc164444d7afb7bf7435a001f2",
            "1ead218e71614374909b92fda097fd42",
            "822bea0ac84d4ff29d984bf5f5d2c3a2",
            "ecef440c871b4daba34661a1ddba6b0c",
            "e633387b1640461e82617c1702ee82f5",
            "26484831a87a4b489e1288ea71ea7767",
            "9f8d631358e240f982e31171d1bd9f26",
            "a0c7029819414c5dacefed93194cd763",
            "f4a01e54ec53475585eaa88b3a272b4b",
            "63c269b37eed4d348f9ce24eef15fc15",
            "a89230859593424e960047a96977c6b8",
            "91163fcffc60438cb39b0eb586dac418",
            "89033e9c0dd249db9dc9a3b1e215dded",
            "73c9d510c8754f2ea21adf318e35bc8e",
            "0fe7751f55134695afb44bf8673dd4d9",
            "f7dd34e15348462297564f0e6e0b568d",
            "537e188c000041fea6adf26f2255d738",
            "39fff32b9756437581228465165a3115",
            "4f75329d3e8d4cc38a405c1c4cc51d70",
            "8bbe22288edf4a06b2c56952fd81d5e7",
            "298f092855f14af79ec2eda792732810",
            "2e6392b95f8a48568a89780adf76387f",
            "55e72b7f262b4f57a6abb1c9f01c8de2",
            "9fbca7fa0d6b4fff910b806a97fa7718",
            "a385bba49b514ab386cb5f4cbb01821f",
            "78a34eb9cd534c3d84c8f22d3c53c88f",
            "cee71fbbf8a04b3bb64b96e7fa2b0b0e",
            "0a0bc95f445948f486fbce865a4642f2",
            "b782092e2282488ba86f85eebe697603",
            "f7ba9e0f4e64484a82374bb5f1d12b15",
            "39c0963803c74ebab07cec20e10d0184",
            "46b69fb951af44f99232f459daa4f103",
            "3e23b4c5848843fcb44dc0ae2f157d66",
            "c9f86634a6bf4e49a902e3d42e67f1bd",
            "03b8a027c56f4b52a3e54f57bb5bb526",
            "58a18918bae34aca8ec73ae89fd5bc24",
            "fd6e1776cbcd4f7b96ec6d9754eb2c83",
            "b5121cada3514b67a9c533e7468b3058",
            "bf70daf78057419b8a78af75a093a3dd",
            "e0b3b3c072be44de8e0a2dae91598aa6",
            "4e21f1bd903443a89dea32bb3f3c26a9",
            "be2be97d4aa64b23beaf316024229a3b",
            "f7416500f850456792cacf42656df46a",
            "482ded5a74484b5f8d8907b4a886f946",
            "3f59849c47ef42d0ac295296a4ad0a91",
            "b1acbd0589c54b5887ea7b3e8b872057",
            "24a119a8500146f28f3d866ed69f7161"
          ]
        },
        "id": "ba0366b5-c9d0-4f7e-97e0-1f964cfad147",
        "outputId": "5602ad04-17c4-431b-e20d-7f0d0c7fd24e",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/user/miniconda/lib/python3.9/site-packages/peft/tuners/tuners_utils.py:543: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be2be97d4aa64b23beaf316024229a3b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying chat template to train dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7416500f850456792cacf42656df46a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing train dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "482ded5a74484b5f8d8907b4a886f946",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Packing train dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f59849c47ef42d0ac295296a4ad0a91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying chat template to eval dataset:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1acbd0589c54b5887ea7b3e8b872057",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing eval dataset:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24a119a8500146f28f3d866ed69f7161",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Packing eval dataset:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=training_arguments,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        "    processing_class=tokenizer,\n",
        "    peft_config=peft_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MtHjukK9xviB",
      "metadata": {
        "id": "MtHjukK9xviB"
      },
      "source": [
        "Here, we launch the training 🔥. Perfect time for you to pause and grab a coffee ☕."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e2df2e9-a82b-4540-aa89-1b40b70a7781",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "9e2df2e9-a82b-4540-aa89-1b40b70a7781",
        "outputId": "113322de-8f42-4285-d58f-8641e6daf295",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [12/12 00:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.236800</td>\n",
              "      <td>1.240833</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/user/miniconda/lib/python3.9/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        }
      ],
      "source": [
        "trainer.train()\n",
        "trainer.save_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d7ea3ab-7c8c-47ad-acd2-99fbe5b68393",
      "metadata": {
        "id": "1d7ea3ab-7c8c-47ad-acd2-99fbe5b68393",
        "tags": []
      },
      "source": [
        "Pushing the Model and the Tokenizer to the Hub\n",
        "\n",
        "Let's push our model and out tokenizer to the Hub ! The model will be pushed under your username + the output_dir that we specified earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "370af020-9319-4ff7-bea1-2842a4847caa",
      "metadata": {
        "id": "370af020-9319-4ff7-bea1-2842a4847caa",
        "tags": [],
        "outputId": "a2d43883-6cc8-4fff-80f9-fd5dbda183f9",
        "colab": {
          "referenced_widgets": [
            "00c6c786a8014635952d94bb505923f1",
            "6945a9a4ba05483e94061404480e2d4f",
            "d56b088f78144a3388749363ee944194",
            "eb6e24851a254a1b81a2032541453ec0",
            "6f268fc2255c46ac99cf15212035009c"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00c6c786a8014635952d94bb505923f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "events.out.tfevents.1739887545.r-jofthomas-fttest-kff5bkw4-24c03-yhiku:   0%|          | 0.00/6.88k [00:00<?, …"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6945a9a4ba05483e94061404480e2d4f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "training_args.bin:   0%|          | 0.00/5.62k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d56b088f78144a3388749363ee944194",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/34.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb6e24851a254a1b81a2032541453ec0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/2.48G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f268fc2255c46ac99cf15212035009c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Jofthomas/gemma-2-2B-it-thinking-function_calling-V0/commit/74db7b9fd8e5c6591db5851db70069bf3016fe50', commit_message='Jofthomas/gemma-2-2B-it-thinking-function_calling-V0', commit_description='', oid='74db7b9fd8e5c6591db5851db70069bf3016fe50', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Jofthomas/gemma-2-2B-it-thinking-function_calling-V0', endpoint='https://huggingface.co', repo_type='model', repo_id='Jofthomas/gemma-2-2B-it-thinking-function_calling-V0'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.push_to_hub(f\"{username}/{output_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83a443ce-5072-4777-8621-cd4faf840410",
      "metadata": {
        "id": "83a443ce-5072-4777-8621-cd4faf840410"
      },
      "source": [
        "Since we also modified the **chat_template** Which is contained in the tokenizer, let's also push the tokenizer with the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d9a86b3-f23d-4060-a97f-b868a7c38c36",
      "metadata": {
        "id": "9d9a86b3-f23d-4060-a97f-b868a7c38c36",
        "outputId": "2726291c-5720-473e-ed92-e4f425f82bae",
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "1a84942726104c7a881b352df849997e"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a84942726104c7a881b352df849997e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Jofthomas/gemma-2-2B-it-thinking-function_calling-V0/commit/5eae94697866df5f9f52bc7c7be677f100a7f339', commit_message='Upload tokenizer', commit_description='', oid='5eae94697866df5f9f52bc7c7be677f100a7f339', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Jofthomas/gemma-2-2B-it-thinking-function_calling-V0', endpoint='https://huggingface.co', repo_type='model', repo_id='Jofthomas/gemma-2-2B-it-thinking-function_calling-V0'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.eos_token = \"<eos>\"\n",
        "# push the tokenizer to hub ( replace with your username and your previously specified\n",
        "tokenizer.push_to_hub(f\"{username}/{output_dir}\", token=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76d275ce-a3e6-4d30-8d8c-0ee274de5370",
      "metadata": {
        "id": "76d275ce-a3e6-4d30-8d8c-0ee274de5370"
      },
      "source": [
        "Test\n",
        "1. Load the adapter from the hub !\n",
        "2. Load the base model : **\"google/gemma-2-2b-it\"** from the hub\n",
        "3. Resize the model to with the new tokens we introduced !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56b89825-70ac-42c1-934c-26e2d54f3b7b",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "390c54434b6448b988ce015eeafe34c9",
            "35b2fe2d357b46488ccef710f2a9bfd7",
            "9c313149d4324bdaa9c8ddc373964d18",
            "4c2546e08a424179af511d8abe3c1c7d",
            "e08b968b1648474e812283fa7c4358a9",
            "bec06c857d234a7ba0593a92272ef764",
            "5608d64f66fa43ef8c162a6e50fb5359",
            "8fd1767e3a8249f5becdab5ca1ccea89",
            "a6173c485914437cb0147583215e8d84"
          ]
        },
        "id": "56b89825-70ac-42c1-934c-26e2d54f3b7b",
        "outputId": "a4cd00b8-61fa-4522-d563-c4ef7e18807d",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c2546e08a424179af511d8abe3c1c7d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e08b968b1648474e812283fa7c4358a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bec06c857d234a7ba0593a92272ef764",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/47.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5608d64f66fa43ef8c162a6e50fb5359",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/34.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8fd1767e3a8249f5becdab5ca1ccea89",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6173c485914437cb0147583215e8d84",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/2.48G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): Gemma2ForCausalLM(\n",
              "      (model): Gemma2Model(\n",
              "        (embed_tokens): lora.Embedding(\n",
              "          (base_layer): Embedding(256006, 2304, padding_idx=0)\n",
              "          (lora_dropout): ModuleDict(\n",
              "            (default): Dropout(p=0.05, inplace=False)\n",
              "          )\n",
              "          (lora_A): ModuleDict()\n",
              "          (lora_B): ModuleDict()\n",
              "          (lora_embedding_A): ParameterDict(  (default): Parameter containing: [torch.cuda.BFloat16Tensor of size 16x256006 (cuda:0)])\n",
              "          (lora_embedding_B): ParameterDict(  (default): Parameter containing: [torch.cuda.BFloat16Tensor of size 2304x16 (cuda:0)])\n",
              "          (lora_magnitude_vector): ModuleDict()\n",
              "        )\n",
              "        (layers): ModuleList(\n",
              "          (0-25): 26 x Gemma2DecoderLayer(\n",
              "            (self_attn): Gemma2Attention(\n",
              "              (q_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2304, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2304, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2304, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2304, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2304, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2304, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2048, out_features=2304, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2304, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): Gemma2RotaryEmbedding()\n",
              "            )\n",
              "            (mlp): Gemma2MLP(\n",
              "              (gate_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2304, out_features=9216, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2304, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=9216, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2304, out_features=9216, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2304, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=9216, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=9216, out_features=2304, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=9216, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2304, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): PytorchGELUTanh()\n",
              "            )\n",
              "            (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "            (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "            (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "            (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "          )\n",
              "        )\n",
              "        (norm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "      )\n",
              "      (lm_head): lora.Linear(\n",
              "        (base_layer): Linear(in_features=2304, out_features=256006, bias=False)\n",
              "        (lora_dropout): ModuleDict(\n",
              "          (default): Dropout(p=0.05, inplace=False)\n",
              "        )\n",
              "        (lora_A): ModuleDict(\n",
              "          (default): Linear(in_features=2304, out_features=16, bias=False)\n",
              "        )\n",
              "        (lora_B): ModuleDict(\n",
              "          (default): Linear(in_features=16, out_features=256006, bias=False)\n",
              "        )\n",
              "        (lora_embedding_A): ParameterDict()\n",
              "        (lora_embedding_B): ParameterDict()\n",
              "        (lora_magnitude_vector): ModuleDict()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "        )\n",
        "\n",
        "peft_model_id = f\"{username}/{output_dir}\" # replace with your newly trained adapter\n",
        "device = \"auto\"\n",
        "config = PeftConfig.from_pretrained(peft_model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,\n",
        "                                             device_map=\"auto\",\n",
        "                                             )\n",
        "tokenizer = AutoTokenizer.from_pretrained(peft_model_id)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model = PeftModel.from_pretrained(model, peft_model_id)\n",
        "model.to(torch.bfloat16)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69e83af9-f967-4e5a-842b-0daed13f7957",
      "metadata": {
        "id": "69e83af9-f967-4e5a-842b-0daed13f7957",
        "outputId": "979b2ee9-fe5b-49b1-aed5-e28f0239a709",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bos><start_of_turn>human\n",
            "You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags.You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions.Here are the available tools:<tools> [{'type': 'function', 'function': {'name': 'convert_currency', 'description': 'Convert from one currency to another', 'parameters': {'type': 'object', 'properties': {'amount': {'type': 'number', 'description': 'The amount to convert'}, 'from_currency': {'type': 'string', 'description': 'The currency to convert from'}, 'to_currency': {'type': 'string', 'description': 'The currency to convert to'}}, 'required': ['amount', 'from_currency', 'to_currency']}}}, {'type': 'function', 'function': {'name': 'calculate_distance', 'description': 'Calculate the distance between two locations', 'parameters': {'type': 'object', 'properties': {'start_location': {'type': 'string', 'description': 'The starting location'}, 'end_location': {'type': 'string', 'description': 'The ending location'}}, 'required': ['start_location', 'end_location']}}}] </tools>Use the following pydantic model json schema for each tool call you will make: {'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
            "<tool_call>\n",
            "{tool_call}\n",
            "</tool_call>Also, before making a call to a function take the time to plan the function to take. Make that thinking process between <think>{your thoughts}</think>\n",
            "\n",
            "Hi, I need to convert 500 USD to Euros. Can you help me with that?<end_of_turn><eos>\n",
            "<start_of_turn>model\n",
            "<think>Alright, so I'm looking at this scenario where the user needs help converting 500 USD to Euros. Let's break it down step by step to understand how to approach this.\n",
            "\n",
            "First, the user has asked for conversion from USD to EUR. I know there's a specific tool available for currency conversion called `convert_currency`. This tool requires three parameters: amount, from_currency, and to_currency. In the user's message, they've provided all necessary details—500 USD and the desire to convert to Euros. \n",
            "\n",
            "I don't need to make any assumptions here because the user has already provided the exact amount and the target currency. My next step is to prepare the function call with the correct parameters. So, I'll structure the request with the amount as 500, from_currency as USD, and to_currency as EUR. \n",
            "\n",
            "This will be sent in JSON format as specified, ensuring that the tool receives all the necessary information to perform the conversion accurately. Once the function is called, it should return the converted amount, which I can then present back to the user.\n",
            "</think><tool_call>\n",
            "{'name': 'convert_currency', 'arguments': {'amount': 500, 'from_currency': 'USD', 'to_currency': 'EUR'}}\n",
            "</tool_call><end_of_turn><eos>\n",
            "<start_of_turn>tool\n",
            "<tool_response>\n",
            "{'converted_amount': 420.5, 'from_currency': 'USD', 'to_currency': 'EUR'}\n",
            "</tool_response><end_of_turn><eos>\n",
            "<start_of_turn>model\n",
            "Sure, 500 USD is approximately 420.50 Euros.<end_of_turn><eos>\n",
            "<start_of_turn>human\n",
            "That's great! Now, can you convert 1000 Euros back to USD?<end_of_turn><eos>\n",
            "<start_of_turn>model\n",
            "<think>Okay, so I'm trying to figure out how to handle the next function call based on the conversation and the previous steps. Let me see...\n",
            "\n",
            "In the conversation, the user first asked to convert 500 USD to Euros, and the model used the `convert_currency` function with the parameters amount=500, from_currency=USD, to_currency=EUR. Then, after getting the response, the model provided the converted amount. Now, the user is asking to convert 1000 Euros back to USD. \n",
            "\n",
            "So, the user's request is clear: convert 1000 EUR to USD. Since the function `convert_currency` is designed to handle currency conversions, and it requires amount, from_currency, and to_currency as parameters, it makes sense to call this function again with the updated values. \n",
            "\n",
            "The amount is 1000, from_currency should be EUR because the user is converting from Euros, and to_currency should be USD because they want the result in US Dollars. I don't need to make any assumptions here because all the required information is provided by the user. \n",
            "\n",
            "I'll structure the function call with these parameters. This should give the user the accurate converted amount from Euros to USD. Once the tool processes this, the model can present the result back to the user.\n",
            "</think><tool_call>\n",
            "{'name': 'convert_currency', 'arguments': {'amount': 1000, 'from_currency': 'EUR', 'to_currency': 'USD'}}\n",
            "</tool_call><end_of_turn><eos>\n",
            "<start_of_turn>tool\n",
            "<tool_response>\n",
            "{'converted_amount': 1190.0, 'from_currency': 'EUR', 'to_currency': 'USD'}\n",
            "</tool_response><end_of_turn><eos>\n",
            "<start_of_turn>model\n",
            "1000 Euros is approximately 1190.00 USD.<end_of_turn><eos>\n",
            "<start_of_turn>human\n",
            "Thank you for your help!<end_of_turn><eos>\n",
            "<start_of_turn>model\n",
            "You're welcome! If you have any other questions, feel free to ask.<end_of_turn><eos>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(dataset[\"test\"][8][\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b47fd511-ea00-47ce-8618-6e78e25672b2",
      "metadata": {
        "id": "b47fd511-ea00-47ce-8618-6e78e25672b2"
      },
      "source": [
        "### Testing the model 🚀\n",
        "\n",
        "In that case, we will take the start of one of the samples from the test set and hope that it will generate the expected output.\n",
        "\n",
        "Since we want to test the function-calling capacities of our newly fine-tuned model, the input will be a user message with the available tools, a\n",
        "\n",
        "\n",
        "### Disclaimer ⚠️\n",
        "\n",
        "The dataset we’re using **does not contain sufficient training data** and is purely for **educational purposes**. As a result, **your trained model’s outputs may differ** from the examples shown in this course. **Don’t be discouraged** if your results vary—our primary goal here is to illustrate the core concepts rather than produce a fully optimized or production-ready model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37bf938d-08fa-4577-9966-0238339afcdb",
      "metadata": {
        "id": "37bf938d-08fa-4577-9966-0238339afcdb",
        "outputId": "e97e7a1e-5ab2-46a2-dc3a-f436964fe004",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bos><start_of_turn>human\n",
            "You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags.You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions.Here are the available tools:<tools> [{'type': 'function', 'function': {'name': 'convert_currency', 'description': 'Convert from one currency to another', 'parameters': {'type': 'object', 'properties': {'amount': {'type': 'number', 'description': 'The amount to convert'}, 'from_currency': {'type': 'string', 'description': 'The currency to convert from'}, 'to_currency': {'type': 'string', 'description': 'The currency to convert to'}}, 'required': ['amount', 'from_currency', 'to_currency']}}}, {'type': 'function', 'function': {'name': 'calculate_distance', 'description': 'Calculate the distance between two locations', 'parameters': {'type': 'object', 'properties': {'start_location': {'type': 'string', 'description': 'The starting location'}, 'end_location': {'type': 'string', 'description': 'The ending location'}}, 'required': ['start_location', 'end_location']}}}] </tools>Use the following pydantic model json schema for each tool call you will make: {'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
            "<tool_call>\n",
            "{tool_call}\n",
            "</tool_call>Also, before making a call to a function take the time to plan the function to take. Make that thinking process between <think>{your thoughts}</think>\n",
            "\n",
            "Hi, I need to convert 500 USD to Euros. Can you help me with that?<end_of_turn><eos>\n",
            "<start_of_turn>model\n",
            "<think>Okay, so the user is asking to convert 500 USD to Euros. I need to figure out how to respond using the available functions. Let me look at the tools provided. There's a function called convert_currency which does exactly that—it converts one currency to another. The parameters required are amount, from_currency, and to_currency. \n",
            "\n",
            "The user provided the amount as 500, the source currency as USD, and the target currency as EUR. That fits perfectly with the function's parameters. I don't need to make any assumptions here because the user has given all the necessary details. \n",
            "\n",
            "So, I should call the convert_currency function with these arguments. That should give the user the converted amount they need.\n",
            "</think><tool_call>\n",
            "{'name': 'convert_currency', 'arguments': {'amount': 500, 'from_currency': 'USD', 'to_currency': 'EUR'}}\n",
            "</tool_call><end_of_turn><eos>\n"
          ]
        }
      ],
      "source": [
        "#this prompt is a sub-sample of one of the test set examples. In this example we start the generation after the model generation starts.\n",
        "prompt=\"\"\"<bos><start_of_turn>human\n",
        "You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags.You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions.Here are the available tools:<tools> [{'type': 'function', 'function': {'name': 'convert_currency', 'description': 'Convert from one currency to another', 'parameters': {'type': 'object', 'properties': {'amount': {'type': 'number', 'description': 'The amount to convert'}, 'from_currency': {'type': 'string', 'description': 'The currency to convert from'}, 'to_currency': {'type': 'string', 'description': 'The currency to convert to'}}, 'required': ['amount', 'from_currency', 'to_currency']}}}, {'type': 'function', 'function': {'name': 'calculate_distance', 'description': 'Calculate the distance between two locations', 'parameters': {'type': 'object', 'properties': {'start_location': {'type': 'string', 'description': 'The starting location'}, 'end_location': {'type': 'string', 'description': 'The ending location'}}, 'required': ['start_location', 'end_location']}}}] </tools>Use the following pydantic model json schema for each tool call you will make: {'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
        "<tool_call>\n",
        "{tool_call}\n",
        "</tool_call>Also, before making a call to a function take the time to plan the function to take. Make that thinking process between <think>{your thoughts}</think>\n",
        "\n",
        "Hi, I need to convert 500 USD to Euros. Can you help me with that?<end_of_turn><eos>\n",
        "<start_of_turn>model\n",
        "<think>\"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
        "inputs = {k: v.to(\"cuda\") for k,v in inputs.items()}\n",
        "outputs = model.generate(**inputs,\n",
        "                         max_new_tokens=300,# Adapt as necessary\n",
        "                         do_sample=True,\n",
        "                         top_p=0.95,\n",
        "                         temperature=0.01,\n",
        "                         repetition_penalty=1.0,\n",
        "                         eos_token_id=tokenizer.eos_token_id)\n",
        "print(tokenizer.decode(outputs[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xWewPCZOyfJQ",
      "metadata": {
        "id": "xWewPCZOyfJQ"
      },
      "source": [
        "## Congratulations\n",
        "Congratulations on finishing this first Bonus Unit 🥳\n",
        "\n",
        "You've just **mastered what Function-Calling is and how to fine-tune your model to do Function-Calling**!\n",
        "\n",
        "If it's the first time you do this, it's normal that you're feeling puzzled. Take time to check the documentation and understand each part of the code and why we did it this way.\n",
        "\n",
        "Also, don't hesitate to try to **fine-tune different models**. The **best way to learn is by trying.**\n",
        "\n",
        "### Keep Learning, Stay Awesome 🤗"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03b8a027c56f4b52a3e54f57bb5bb526": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a0bc95f445948f486fbce865a4642f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0fe7751f55134695afb44bf8673dd4d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ead218e71614374909b92fda097fd42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26484831a87a4b489e1288ea71ea7767": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "298f092855f14af79ec2eda792732810": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a385bba49b514ab386cb5f4cbb01821f",
            "placeholder": "​",
            "style": "IPY_MODEL_78a34eb9cd534c3d84c8f22d3c53c88f",
            "value": "Tokenizing eval dataset: 100%"
          }
        },
        "2ccddb85840c4981ae089ae4c74a2de6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89eee480405a416ba0edf097423724b9",
              "IPY_MODEL_56e8079c374a4f3f9af5ef96a73f2955",
              "IPY_MODEL_3aeb28bc164444d7afb7bf7435a001f2"
            ],
            "layout": "IPY_MODEL_1ead218e71614374909b92fda097fd42"
          }
        },
        "2e6392b95f8a48568a89780adf76387f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cee71fbbf8a04b3bb64b96e7fa2b0b0e",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a0bc95f445948f486fbce865a4642f2",
            "value": 10
          }
        },
        "328fa6d902bd46bbb0ecdc7404a13e8c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33ec043a635f4e99b67cd6f7e6fc6193": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36bbd4bd563a4053a7af8532300253b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33ec043a635f4e99b67cd6f7e6fc6193",
            "placeholder": "​",
            "style": "IPY_MODEL_39fee7a249c146d1a166e58755c1cda8",
            "value": " 100/100 [00:00&lt;00:00, 277.78 examples/s]"
          }
        },
        "39c0963803c74ebab07cec20e10d0184": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46b69fb951af44f99232f459daa4f103",
              "IPY_MODEL_3e23b4c5848843fcb44dc0ae2f157d66",
              "IPY_MODEL_c9f86634a6bf4e49a902e3d42e67f1bd"
            ],
            "layout": "IPY_MODEL_03b8a027c56f4b52a3e54f57bb5bb526"
          }
        },
        "39fee7a249c146d1a166e58755c1cda8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39fff32b9756437581228465165a3115": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aeb28bc164444d7afb7bf7435a001f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f8d631358e240f982e31171d1bd9f26",
            "placeholder": "​",
            "style": "IPY_MODEL_a0c7029819414c5dacefed93194cd763",
            "value": " 100/100 [00:00&lt;00:00, 648.06 examples/s]"
          }
        },
        "3b07ec7f4d024b61abe94c8adeebed55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e23b4c5848843fcb44dc0ae2f157d66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5121cada3514b67a9c533e7468b3058",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf70daf78057419b8a78af75a093a3dd",
            "value": 10
          }
        },
        "46b69fb951af44f99232f459daa4f103": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58a18918bae34aca8ec73ae89fd5bc24",
            "placeholder": "​",
            "style": "IPY_MODEL_fd6e1776cbcd4f7b96ec6d9754eb2c83",
            "value": "Packing eval dataset: 100%"
          }
        },
        "472cbf91b24f46829960d68e2316c417": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2157c83879046a29b72613bce9de56e",
            "placeholder": "​",
            "style": "IPY_MODEL_3b07ec7f4d024b61abe94c8adeebed55",
            "value": "Applying chat template to train dataset: 100%"
          }
        },
        "4d006dc72b2b45b58caf4d398c3756b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_328fa6d902bd46bbb0ecdc7404a13e8c",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f375fed157034dfcbd28744027d77eba",
            "value": 100
          }
        },
        "4e21f1bd903443a89dea32bb3f3c26a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f75329d3e8d4cc38a405c1c4cc51d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "537e188c000041fea6adf26f2255d738": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55e72b7f262b4f57a6abb1c9f01c8de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b782092e2282488ba86f85eebe697603",
            "placeholder": "​",
            "style": "IPY_MODEL_f7ba9e0f4e64484a82374bb5f1d12b15",
            "value": " 10/10 [00:00&lt;00:00, 154.34 examples/s]"
          }
        },
        "56e8079c374a4f3f9af5ef96a73f2955": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e633387b1640461e82617c1702ee82f5",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26484831a87a4b489e1288ea71ea7767",
            "value": 100
          }
        },
        "57d137229091486dbf0e4b7dd6dce98a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4c43d908bd64d9bbdb488dac46d2e45",
            "placeholder": "​",
            "style": "IPY_MODEL_96691a6287ef401582a2a1744a4940c4",
            "value": "Tokenizing train dataset: 100%"
          }
        },
        "58a18918bae34aca8ec73ae89fd5bc24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63c269b37eed4d348f9ce24eef15fc15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73c9d510c8754f2ea21adf318e35bc8e",
            "placeholder": "​",
            "style": "IPY_MODEL_0fe7751f55134695afb44bf8673dd4d9",
            "value": "Applying chat template to eval dataset: 100%"
          }
        },
        "73c9d510c8754f2ea21adf318e35bc8e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78a34eb9cd534c3d84c8f22d3c53c88f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "822bea0ac84d4ff29d984bf5f5d2c3a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89033e9c0dd249db9dc9a3b1e215dded": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89eee480405a416ba0edf097423724b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_822bea0ac84d4ff29d984bf5f5d2c3a2",
            "placeholder": "​",
            "style": "IPY_MODEL_ecef440c871b4daba34661a1ddba6b0c",
            "value": "Packing train dataset: 100%"
          }
        },
        "8bbe22288edf4a06b2c56952fd81d5e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_298f092855f14af79ec2eda792732810",
              "IPY_MODEL_2e6392b95f8a48568a89780adf76387f",
              "IPY_MODEL_55e72b7f262b4f57a6abb1c9f01c8de2"
            ],
            "layout": "IPY_MODEL_9fbca7fa0d6b4fff910b806a97fa7718"
          }
        },
        "91163fcffc60438cb39b0eb586dac418": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39fff32b9756437581228465165a3115",
            "placeholder": "​",
            "style": "IPY_MODEL_4f75329d3e8d4cc38a405c1c4cc51d70",
            "value": " 10/10 [00:00&lt;00:00, 298.91 examples/s]"
          }
        },
        "952893c941c346c2aedcd9358859a3b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96691a6287ef401582a2a1744a4940c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f8d631358e240f982e31171d1bd9f26": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fbca7fa0d6b4fff910b806a97fa7718": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0c7029819414c5dacefed93194cd763": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a385bba49b514ab386cb5f4cbb01821f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a89230859593424e960047a96977c6b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7dd34e15348462297564f0e6e0b568d",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_537e188c000041fea6adf26f2255d738",
            "value": 10
          }
        },
        "b1542891fc6243d98d51981dd0584bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d36e7dd4b9dc497faa6e8f63843a738f",
            "placeholder": "​",
            "style": "IPY_MODEL_f469ec8c79ac476c82a5e228f347bffa",
            "value": " 100/100 [00:00&lt;00:00, 690.13 examples/s]"
          }
        },
        "b2e16ad7540d4760b28f3a8c419905f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4c43d908bd64d9bbdb488dac46d2e45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5121cada3514b67a9c533e7468b3058": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b782092e2282488ba86f85eebe697603": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd746ea2e46a491e954ac6f32fb0e45b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6f810bd430245b190ee932554cca05c",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_952893c941c346c2aedcd9358859a3b9",
            "value": 100
          }
        },
        "bf70daf78057419b8a78af75a093a3dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9f86634a6bf4e49a902e3d42e67f1bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0b3b3c072be44de8e0a2dae91598aa6",
            "placeholder": "​",
            "style": "IPY_MODEL_4e21f1bd903443a89dea32bb3f3c26a9",
            "value": " 10/10 [00:00&lt;00:00, 312.22 examples/s]"
          }
        },
        "cacc3c3a10c64b338866a8e42201e44c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cee71fbbf8a04b3bb64b96e7fa2b0b0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d36e7dd4b9dc497faa6e8f63843a738f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0b3b3c072be44de8e0a2dae91598aa6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3fe61834c3e49a3895212a336776f9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_472cbf91b24f46829960d68e2316c417",
              "IPY_MODEL_bd746ea2e46a491e954ac6f32fb0e45b",
              "IPY_MODEL_b1542891fc6243d98d51981dd0584bdf"
            ],
            "layout": "IPY_MODEL_b2e16ad7540d4760b28f3a8c419905f8"
          }
        },
        "e633387b1640461e82617c1702ee82f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6f810bd430245b190ee932554cca05c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9de72aadc5743a2b56537b3ad035461": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57d137229091486dbf0e4b7dd6dce98a",
              "IPY_MODEL_4d006dc72b2b45b58caf4d398c3756b8",
              "IPY_MODEL_36bbd4bd563a4053a7af8532300253b7"
            ],
            "layout": "IPY_MODEL_cacc3c3a10c64b338866a8e42201e44c"
          }
        },
        "ecef440c871b4daba34661a1ddba6b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2157c83879046a29b72613bce9de56e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f375fed157034dfcbd28744027d77eba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f469ec8c79ac476c82a5e228f347bffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4a01e54ec53475585eaa88b3a272b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63c269b37eed4d348f9ce24eef15fc15",
              "IPY_MODEL_a89230859593424e960047a96977c6b8",
              "IPY_MODEL_91163fcffc60438cb39b0eb586dac418"
            ],
            "layout": "IPY_MODEL_89033e9c0dd249db9dc9a3b1e215dded"
          }
        },
        "f7ba9e0f4e64484a82374bb5f1d12b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7dd34e15348462297564f0e6e0b568d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd6e1776cbcd4f7b96ec6d9754eb2c83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a67179783d745b8a836e30ca9821143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d42aaa00581a461f96928a2fdb9c9adf",
              "IPY_MODEL_5e88178b56de467cbd19cdee3f675094",
              "IPY_MODEL_b7ed19a7a6ba4fda8d0d483fdd6e48f6"
            ],
            "layout": "IPY_MODEL_63e312f67e9b44c2950848012e0e6ff6"
          }
        },
        "d42aaa00581a461f96928a2fdb9c9adf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cb096dcc7144beab982d7449bdb7cf5",
            "placeholder": "​",
            "style": "IPY_MODEL_9efbb12684a4449bb9569957dfdbf8c3",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "5e88178b56de467cbd19cdee3f675094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7879a50638214dcbaffe3b6e95ad3322",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cbb19ca98e04493abad7867edc2a63bd",
            "value": 2
          }
        },
        "b7ed19a7a6ba4fda8d0d483fdd6e48f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5d220c05ac34aa194cf838a45422649",
            "placeholder": "​",
            "style": "IPY_MODEL_5b30f7da57de47ee97f6ee8bf9c35ba2",
            "value": " 2/2 [00:24&lt;00:00, 10.39s/it]"
          }
        },
        "63e312f67e9b44c2950848012e0e6ff6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cb096dcc7144beab982d7449bdb7cf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9efbb12684a4449bb9569957dfdbf8c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7879a50638214dcbaffe3b6e95ad3322": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbb19ca98e04493abad7867edc2a63bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5d220c05ac34aa194cf838a45422649": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b30f7da57de47ee97f6ee8bf9c35ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}